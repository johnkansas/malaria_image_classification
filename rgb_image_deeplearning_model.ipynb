{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rgb_image_deeplearning_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoNe5GeHernNiJ7VeTRrNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnkansas/malaria_image_classification/blob/main/rgb_image_deeplearning_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qdq_Eo4MhA74"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옆에 파일 부분에 구글 드라이브에 접속 할수 있음 >> 목표는 zip 파일을 여는것.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1FBbPJ4jQ4c",
        "outputId": "dab20a2c-9267-484b-8759-99186fa85014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://lhncbc.nlm.nih.gov/LHC-downloads/downloads.html#malaria-datasets\n",
        "\n",
        "여기 링크에 가서 데이터 다운로드\n",
        "다운로드된 파일을 test,train , parasitized, uninfected으로 나누어서 class를 자동으로 분류하는 코드 만들기\n",
        "\n",
        "unzip을 하면 바로 현재 위치에서 파일 확인 가능"
      ],
      "metadata": {
        "id": "46YEpc0UEnS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/My Drive/malaria/cell_images.zip\""
      ],
      "metadata": {
        "id": "VI1Fu9ZKjWxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = \"test/\"\n",
        "train_path = \"train/\""
      ],
      "metadata": {
        "id": "TDxB8JpGjZYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as imread"
      ],
      "metadata": {
        "id": "ZzL0mHM4jiFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "ed3qDCGVlEEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래는 datasets.imagefolder 코드를 쓸때 colab에서 생기는 버그를 해결한 내용."
      ],
      "metadata": {
        "id": "fjVA0aypS4y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R train/.ipynb_checkpoints\n",
        "!ls train/ -a  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25aiQHDmDCyT",
        "outputId": "10fb7cf6-72f0-4e1a-ea69-adb48f184707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'train/.ipynb_checkpoints': No such file or directory\n",
            ".  ..  Parasitized  Uninfected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R test/.ipynb_checkpoints\n",
        "!ls test/ -a "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS3fuOCoDLyI",
        "outputId": "17525af4-52d4-4a65-b99d-128c9a9f0e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  Parasitized  Uninfected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 사이즈를 지정해주고,transforms코드를 활용해 데이터를 미리 코드에 잘 적용 될수 있도록 만들어 줍니다."
      ],
      "metadata": {
        "id": "QtmMJGZ6Ti72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (130, 130)"
      ],
      "metadata": {
        "id": "wO02vAS-SP2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform=transforms.Compose([\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "EzahUA-NIem8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMPLE USAGE:\n",
        "# instantiate the dataset and dataloader\n",
        "\n",
        "testset = datasets.ImageFolder(\"./test\",transform=test_transform) # our custom dataset\n",
        "testloader = DataLoader(testset,batch_size=16)\n",
        "trainset = datasets.ImageFolder(train_path,train_transform) # our custom dataset\n",
        "trainloader = DataLoader(trainset,batch_size=16, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# iterate over data\n",
        "for inputs, labels in trainloader:\n",
        "    # use the above variables freely\n",
        "    print(inputs.size(),inputs.sum(), labels)\n",
        "print(len(testset))\n",
        "# for inputs, labels, paths in trainloader:\n",
        "#     # use the above variables freely\n",
        "#     print(inputs, labels, paths)"
      ],
      "metadata": {
        "id": "DIccU4l-6PHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(W-F+2*P)/S +1=output size\n",
        "\n",
        "\n",
        "W: image width >>input size\n",
        "\n",
        "\n",
        "F: filter width >> channel의 개수\n",
        "\n",
        "\n",
        "P: padding size >> 계산 할때 데이터 보존하기 위한 방법\n",
        "\n",
        "\n",
        "S: stride number >> 계산 시간을 단축하기 위해 띄엄띄엄 계산하기"
      ],
      "metadata": {
        "id": "tPIIv6yTT2UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(12544, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sig=nn.Sigmoid()\n",
        "        self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))#>>64,64,32\n",
        "        x = self.pool(F.relu(self.conv2(x)))#>>31,31,64\n",
        "        x = self.pool(F.relu(self.conv3(x)))#>>14,14,64\n",
        "        x = torch.flatten(x,1) # flatten all dimensions except batch>>12544\n",
        "        # print(\"after flatten\",x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        # print(\"after drop\",x.size())\n",
        "        x = self.fc2(x)\n",
        "        x = self.sig(x)\n",
        "        # print(\"after fc2\",x.size())\n",
        "        # x=x.squeeze()\n",
        "        # x=torch.FloatTensor(x)\n",
        "        # torch.reshape(x, (-1,))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "# 출력 사이즈 생성자 만들때 뭐 넣을지 아무것도 지정 안함.\n",
        "# fc에 비해 계산이 까다로움 >> 입출력이 맞아야함."
      ],
      "metadata": {
        "id": "82k5thUjhX_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이진 분류 방법인 binary cross entropy 사용\n",
        "\n",
        "\n",
        "adam이 가장 좋은것으로 알려져 있어서 사용"
      ],
      "metadata": {
        "id": "naKDxWSgUwCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)#optimizer 안에 넣는다."
      ],
      "metadata": {
        "id": "9m3tk5BdhbOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 시킨 결과 loss가 줄어든 모습 확인 가능"
      ],
      "metadata": {
        "id": "RjQRncUaU_Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):  # loop over the dataset multiple times# trainer의 train함수\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs =net(inputs)\n",
        "        oo=torch.flatten(outputs)\n",
        "        loss = criterion(oo,labels.type(torch.FloatTensor))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gs6kEtYhd3h",
        "outputId": "e6d916de-1da5-41b8-86c8-a7177663df31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  1000] loss: 0.086\n",
            "[2,  1000] loss: 0.084\n",
            "[3,  1000] loss: 0.083\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습에 사용했던 \n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "매개변수 저장"
      ],
      "metadata": {
        "id": "t9Q1W9MTVFVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "2C89Clsdhg7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습에 사용했던 매개변수 불러오기\n",
        "\n"
      ],
      "metadata": {
        "id": "x8cKeHfJVLOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybpi54ttiBLq",
        "outputId": "6b93f908-f9a8-4f82-efb3-948649f860bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 검증 결과 0.5크기로 분류하여 정답률이 더 낮을수도 있습니다."
      ],
      "metadata": {
        "id": "R0dkKjjqVTDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        oo=torch.flatten(outputs)\n",
        "        for i in range(len(oo)):\n",
        "          total+=1\n",
        "          if oo[i]>0.5:\n",
        "            a=1\n",
        "          elif oo[i]<0.5:\n",
        "            a=0\n",
        "          if a==labels[i]:\n",
        "            correct+=1\n",
        "\n",
        "print(f'Accuracy of the network on the 5512 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfhdZun6iGR6",
        "outputId": "ed72b34d-26b5-4db0-f05a-d13b721b6d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 5512 test images: 93 %\n"
          ]
        }
      ]
    }
  ]
}